{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Open Deep Research - Supervisor-Researcher Architecture\n",
    "\n",
    "In this notebook, we'll explore the **supervisor-researcher delegation architecture** for conducting deep research with LangGraph.\n",
    "\n",
    "You can visit this repository to see the original application: [Open Deep Research](https://github.com/langchain-ai/open_deep_research)\n",
    "\n",
    "Let's jump in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We're Building\n",
    "\n",
    "This implementation uses a **hierarchical delegation pattern** where:\n",
    "\n",
    "1. **User Clarification** - Optionally asks clarifying questions to understand the research scope\n",
    "2. **Research Brief Generation** - Transforms user messages into a structured research brief\n",
    "3. **Supervisor** - A lead researcher that analyzes the brief and delegates research tasks\n",
    "4. **Parallel Researchers** - Multiple sub-agents that conduct focused research simultaneously\n",
    "5. **Research Compression** - Each researcher synthesizes their findings\n",
    "6. **Final Report** - All findings are combined into a comprehensive report\n",
    "\n",
    "![Architecture Diagram](https://i.imgur.com/Q8HEZn0.png)\n",
    "\n",
    "This differs from a section-based approach by allowing dynamic task decomposition based on the research question, rather than predefined sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ü§ù Breakout Room #1\n",
    "## Deep Research Foundations\n",
    "\n",
    "In this breakout room, we'll understand the architecture and components of the Open Deep Research system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies\n",
    "\n",
    "You'll need API keys for Anthropic (for the LLM) and Tavily (for web search). We'll configure the system to use Anthropic's Claude Sonnet 4 exclusively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set API Keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# Tavily API Key for web search\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.environ.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: State Definitions\n",
    "\n",
    "The state structure is hierarchical with three levels:\n",
    "\n",
    "### Agent State (Top Level)\n",
    "Contains the overall conversation messages, research brief, accumulated notes, and final report.\n",
    "\n",
    "### Supervisor State (Middle Level)\n",
    "Manages the research supervisor's messages, research iterations, and coordinating parallel researchers.\n",
    "\n",
    "### Researcher State (Bottom Level)\n",
    "Each individual researcher has their own message history, tool call iterations, and research findings.\n",
    "\n",
    "We also have structured outputs for tool calling:\n",
    "- **ConductResearch** - Tool for supervisor to delegate research to a sub-agent\n",
    "- **ResearchComplete** - Tool to signal research phase is done\n",
    "- **ClarifyWithUser** - Structured output for asking clarifying questions\n",
    "- **ResearchQuestion** - Structured output for the research brief\n",
    "\n",
    "Let's import these from our library: [`open_deep_library/state.py`](open_deep_library/state.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import state definitions from the library\n",
    "from open_deep_library.state import (\n",
    "    # Main workflow states\n",
    "    AgentState,           # Lines 65-72: Top-level agent state with messages, research_brief, notes, final_report\n",
    "    AgentInputState,      # Lines 62-63: Input state is just messages\n",
    "    \n",
    "    # Supervisor states\n",
    "    SupervisorState,      # Lines 74-81: Supervisor manages research delegation and iterations\n",
    "    \n",
    "    # Researcher states\n",
    "    ResearcherState,      # Lines 83-90: Individual researcher with messages and tool iterations\n",
    "    ResearcherOutputState, # Lines 92-96: Output from researcher (compressed research + raw notes)\n",
    "    \n",
    "    # Structured outputs for tool calling\n",
    "    ConductResearch,      # Lines 15-19: Tool for delegating research to sub-agents\n",
    "    ResearchComplete,     # Lines 21-22: Tool to signal research completion\n",
    "    ClarifyWithUser,      # Lines 30-41: Structured output for user clarification\n",
    "    ResearchQuestion,     # Lines 43-48: Structured output for research brief\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Utility Functions and Tools\n",
    "\n",
    "The system uses several key utilities:\n",
    "\n",
    "### Search Tools\n",
    "- **tavily_search** - Async web search with automatic summarization to stay within token limits\n",
    "- Supports Anthropic native web search and Tavily API\n",
    "\n",
    "### Reflection Tools\n",
    "- **think_tool** - Allows researchers to reflect on their progress and plan next steps (ReAct pattern)\n",
    "\n",
    "### Helper Utilities\n",
    "- **get_all_tools** - Assembles the complete toolkit (search + MCP + reflection)\n",
    "- **get_today_str** - Provides current date context for research\n",
    "- Token limit handling utilities for graceful degradation\n",
    "\n",
    "These are defined in [`open_deep_library/utils.py`](open_deep_library/utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions and tools from the library\n",
    "from open_deep_library.utils import (\n",
    "    # Search tool - Lines 43-136: Tavily search with automatic summarization\n",
    "    tavily_search,\n",
    "    \n",
    "    # Reflection tool - Lines 219-244: Strategic thinking tool for ReAct pattern\n",
    "    think_tool,\n",
    "    \n",
    "    # Tool assembly - Lines 569-597: Get all configured tools\n",
    "    get_all_tools,\n",
    "    \n",
    "    # Date utility - Lines 872-879: Get formatted current date\n",
    "    get_today_str,\n",
    "    \n",
    "    # Supporting utilities for error handling\n",
    "    get_api_key_for_model,          # Lines 892-914: Get API keys from config or env\n",
    "    is_token_limit_exceeded,         # Lines 665-701: Detect token limit errors\n",
    "    get_model_token_limit,           # Lines 831-846: Look up model's token limit\n",
    "    remove_up_to_last_ai_message,    # Lines 848-866: Truncate messages for retry\n",
    "    anthropic_websearch_called,      # Lines 607-637: Detect Anthropic native search usage\n",
    "    openai_websearch_called,         # Lines 639-658: Detect OpenAI native search usage\n",
    "    get_notes_from_tool_calls,       # Lines 599-601: Extract notes from tool messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Configuration System\n",
    "\n",
    "The configuration system controls:\n",
    "\n",
    "### Research Behavior\n",
    "- **allow_clarification** - Whether to ask clarifying questions before research\n",
    "- **max_concurrent_research_units** - How many parallel researchers can run (default: 5)\n",
    "- **max_researcher_iterations** - How many times supervisor can delegate research (default: 6)\n",
    "- **max_react_tool_calls** - Tool call limit per researcher (default: 10)\n",
    "\n",
    "### Model Configuration\n",
    "- **research_model** - Model for research and supervision (we'll use Anthropic)\n",
    "- **compression_model** - Model for synthesizing findings\n",
    "- **final_report_model** - Model for writing the final report\n",
    "- **summarization_model** - Model for summarizing web search results\n",
    "\n",
    "### Search Configuration\n",
    "- **search_api** - Which search API to use (ANTHROPIC, TAVILY, or NONE)\n",
    "- **max_content_length** - Character limit before summarization\n",
    "\n",
    "Defined in [`open_deep_library/configuration.py`](open_deep_library/configuration.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration from the library\n",
    "from open_deep_library.configuration import (\n",
    "    Configuration,    # Lines 38-247: Main configuration class with all settings\n",
    "    SearchAPI,        # Lines 11-17: Enum for search API options (ANTHROPIC, TAVILY, NONE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Prompt Templates\n",
    "\n",
    "The system uses carefully engineered prompts for each phase:\n",
    "\n",
    "### Phase 1: Clarification\n",
    "**clarify_with_user_instructions** - Analyzes if the research scope is clear or needs clarification\n",
    "\n",
    "### Phase 2: Research Brief\n",
    "**transform_messages_into_research_topic_prompt** - Converts user messages into a detailed research brief\n",
    "\n",
    "### Phase 3: Supervisor\n",
    "**lead_researcher_prompt** - System prompt for the supervisor that manages delegation strategy\n",
    "\n",
    "### Phase 4: Researcher\n",
    "**research_system_prompt** - System prompt for individual researchers conducting focused research\n",
    "\n",
    "### Phase 5: Compression\n",
    "**compress_research_system_prompt** - Prompt for synthesizing research findings without losing information\n",
    "\n",
    "### Phase 6: Final Report\n",
    "**final_report_generation_prompt** - Comprehensive prompt for writing the final report\n",
    "\n",
    "All prompts are defined in [`open_deep_library/prompts.py`](open_deep_library/prompts.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prompt templates from the library\n",
    "from open_deep_library.prompts import (\n",
    "    clarify_with_user_instructions,                    # Lines 3-41: Ask clarifying questions\n",
    "    transform_messages_into_research_topic_prompt,     # Lines 44-77: Generate research brief\n",
    "    lead_researcher_prompt,                            # Lines 79-136: Supervisor system prompt\n",
    "    research_system_prompt,                            # Lines 138-183: Researcher system prompt\n",
    "    compress_research_system_prompt,                   # Lines 186-222: Research compression prompt\n",
    "    final_report_generation_prompt,                    # Lines 228-308: Final report generation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #1:\n",
    "\n",
    "Explain the interrelationships between the three states (Agent, Supervisor, Researcher). Why don't we just make a single huge state?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer: The hierarchical three state architecture is a deliberate design pattern that solves several critical problems in multi-agent systems. \n",
    "1. Each state level has its own responsibilities: Agent manages the overall conversation context, final report and user-facing information; Supervisor handles coordination logic and research iterations; Researcher is specialized for gathering context using tools and findings.\n",
    "\n",
    "If everything lived in one huge state, we'd have chaotic mixing of user messages and internal researcher tool outputs, all of the outputs polluting final reports, and individual researchers iterations visible to all other researchers.\n",
    "\n",
    "Other problem includes context bloat where each researcher would be doing max 5 iterations furthermore confusing the LLM with irrelevant context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #2:\n",
    "\n",
    "What are the advantages and disadvantages of importing these components instead of including them in the notebook?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer: \n",
    "\n",
    "Advantage: shared components across multiple notebooks/projects, better development experience - everything we need to change or use is in one place, organized; readability and most important abstraction.\n",
    "\n",
    "Disadvantages: cannot share just the notebook with someone, context switching, relying on dependecies import, path and environment management, worse debugging experience - when changing something we need to refresh imported files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Activity #1: Explore the Prompts\n",
    "\n",
    "Open `open_deep_library/prompts.py` and examine one of the prompt templates in detail.\n",
    "\n",
    "**Requirements:**\n",
    "1. Choose one prompt template (clarify, brief, supervisor, researcher, compression, or final report)\n",
    "2. Explain what the prompt is designed to accomplish\n",
    "3. Identify 2-3 key techniques used in the prompt (e.g., structured output, role definition, examples)\n",
    "4. Suggest one improvement you might make to the prompt\n",
    "\n",
    "**YOUR CODE HERE** - Write your analysis in a markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. research_system_prompt\n",
    "2. this prompt is designed to create a bounded, strategic research agent that mimics human research behavior.\n",
    "\n",
    "3. \n",
    "- a) \"You are a research assistant conducting research on the user's input topic. For context, today's date is {date}.\" - role clarity, he knows his job is research assistant (not supervisor or expert) \n",
    "- b) \"<Hard Limits>\n",
    "    **Tool Call Budgets** (Prevent excessive searching):\n",
    "    - **Simple queries**: Use 2-3 search tool calls maximum\n",
    "    - **Complex queries**: Use up to 5 search tool calls maximum\n",
    "    - **Always stop**: After 5 search tool calls if you cannot find the right sources\" - limiting researcher to cut costs and not get stuck in a loop.\n",
    "- c) \"<Show Your Thinking>\n",
    "    After each search tool call, use think_tool to analyze the results:\n",
    "    - What key information did I find?\n",
    "    - What's missing?\n",
    "    - Do I have enough to answer the question comprehensively?\n",
    "    - Should I search more or provide my answer?\n",
    "    </Show Your Thinking>\" - forcing the agent to evaluate its own progress and discourages him from blindly calling multiple searches in parallel without assessment. (We should learn from this to sometimes stop and process what we just read or saw :)\n",
    "    \n",
    "4. Early exit heuristics with examples\n",
    "Current problem is that agents overshoot because they're unsure if they've met the threshold.\n",
    "\n",
    "Proposed addition to the stop/exit criteria:\n",
    "\"\"\"\n",
    "Example 1 - Simple Query:\n",
    "Question: \"What is the capital of France?\"\n",
    "STOP after 1 search: Found \"Paris\" from reliable source (eg. Wikipedia)\n",
    "DON'T search for: \"history of Paris\", \"Paris population\", \"Paris landmarks\"\n",
    "\n",
    "Example 2 - Complex Query:\n",
    "Question: \"What are evidence-based stress management techniques?\"\n",
    "STOP after 3 searches when you have:\n",
    "- 5+ distinct techniques with explanations\n",
    "- Scientific backing (studies, expert sources)\n",
    "- Practical implementation steps\n",
    "DON'T search for: Every possible technique, minute details on neuroscience\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ü§ù Breakout Room #2\n",
    "## Building & Running the Researcher\n",
    "\n",
    "In this breakout room, we'll explore the node functions, build the graph, and run wellness research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Node Functions - The Building Blocks\n",
    "\n",
    "Now let's look at the node functions that make up our graph. We'll import them from the library and understand what each does.\n",
    "\n",
    "### The Complete Research Workflow\n",
    "\n",
    "The workflow consists of 8 key nodes organized into 3 subgraphs:\n",
    "\n",
    "1. **Main Graph Nodes:**\n",
    "   - `clarify_with_user` - Entry point that checks if clarification is needed\n",
    "   - `write_research_brief` - Transforms user input into structured research brief\n",
    "   - `final_report_generation` - Synthesizes all research into final report\n",
    "\n",
    "2. **Supervisor Subgraph Nodes:**\n",
    "   - `supervisor` - Lead researcher that plans and delegates\n",
    "   - `supervisor_tools` - Executes supervisor's tool calls (delegation, reflection)\n",
    "\n",
    "3. **Researcher Subgraph Nodes:**\n",
    "   - `researcher` - Individual researcher conducting focused research\n",
    "   - `researcher_tools` - Executes researcher's tool calls (search, reflection)\n",
    "   - `compress_research` - Synthesizes researcher's findings\n",
    "\n",
    "All nodes are defined in [`open_deep_library/deep_researcher.py`](open_deep_library/deep_researcher.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 1: clarify_with_user\n",
    "\n",
    "**Purpose:** Analyzes user messages and asks clarifying questions if the research scope is unclear.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Check if clarification is enabled in configuration\n",
    "2. Use structured output to analyze if clarification is needed\n",
    "3. If needed, end with a clarifying question for the user\n",
    "4. If not needed, proceed to research brief with verification message\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 60-115](open_deep_library/deep_researcher.py#L60-L115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the clarify_with_user node\n",
    "from open_deep_library.deep_researcher import clarify_with_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 2: write_research_brief\n",
    "\n",
    "**Purpose:** Transforms user messages into a structured research brief for the supervisor.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Use structured output to generate detailed research brief from messages\n",
    "2. Initialize supervisor with system prompt and research brief\n",
    "3. Set up supervisor messages with proper context\n",
    "\n",
    "**Why this matters:** A well-structured research brief helps the supervisor make better delegation decisions.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 118-175](open_deep_library/deep_researcher.py#L118-L175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the write_research_brief node\n",
    "from open_deep_library.deep_researcher import write_research_brief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 3: supervisor\n",
    "\n",
    "**Purpose:** Lead research supervisor that plans research strategy and delegates to sub-researchers.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Configure model with three tools:\n",
    "   - `ConductResearch` - Delegate research to a sub-agent\n",
    "   - `ResearchComplete` - Signal that research is done\n",
    "   - `think_tool` - Strategic reflection before decisions\n",
    "2. Generate response based on current context\n",
    "3. Increment research iteration count\n",
    "4. Proceed to tool execution\n",
    "\n",
    "**Decision Making:** The supervisor uses `think_tool` to reflect before delegating research, ensuring thoughtful decomposition of the research question.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 178-223](open_deep_library/deep_researcher.py#L178-L223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the supervisor node (from supervisor subgraph)\n",
    "from open_deep_library.deep_researcher import supervisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 4: supervisor_tools\n",
    "\n",
    "**Purpose:** Executes the supervisor's tool calls, including strategic thinking and research delegation.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Check exit conditions:\n",
    "   - Exceeded maximum iterations\n",
    "   - No tool calls made\n",
    "   - `ResearchComplete` called\n",
    "2. Process `think_tool` calls for strategic reflection\n",
    "3. Execute `ConductResearch` calls in parallel:\n",
    "   - Spawn researcher subgraphs for each delegation\n",
    "   - Limit to `max_concurrent_research_units` (default: 5)\n",
    "   - Gather all results asynchronously\n",
    "4. Aggregate findings and return to supervisor\n",
    "\n",
    "**Parallel Execution:** This is where the magic happens - multiple researchers work simultaneously on different aspects of the research question.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 225-349](open_deep_library/deep_researcher.py#L225-L349)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the supervisor_tools node\n",
    "from open_deep_library.deep_researcher import supervisor_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 5: researcher\n",
    "\n",
    "**Purpose:** Individual researcher that conducts focused research on a specific topic.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Load all available tools (search, MCP, reflection)\n",
    "2. Configure model with tools and researcher system prompt\n",
    "3. Generate response with tool calls\n",
    "4. Increment tool call iteration count\n",
    "\n",
    "**ReAct Pattern:** Researchers use `think_tool` to reflect after each search, deciding whether to continue or provide their answer.\n",
    "\n",
    "**Available Tools:**\n",
    "- Search tools (Tavily or Anthropic native search)\n",
    "- `think_tool` for strategic reflection\n",
    "- `ResearchComplete` to signal completion\n",
    "- MCP tools (if configured)\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 365-424](open_deep_library/deep_researcher.py#L365-L424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the researcher node (from researcher subgraph)\n",
    "from open_deep_library.deep_researcher import researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 6: researcher_tools\n",
    "\n",
    "**Purpose:** Executes the researcher's tool calls, including searches and strategic reflection.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Check early exit conditions (no tool calls, native search used)\n",
    "2. Execute all tool calls in parallel:\n",
    "   - Search tools fetch and summarize web content\n",
    "   - `think_tool` records strategic reflections\n",
    "   - MCP tools execute external integrations\n",
    "3. Check late exit conditions:\n",
    "   - Exceeded `max_react_tool_calls` (default: 10)\n",
    "   - `ResearchComplete` called\n",
    "4. Continue research loop or proceed to compression\n",
    "\n",
    "**Error Handling:** Safely handles tool execution errors and continues with available results.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 435-509](open_deep_library/deep_researcher.py#L435-L509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the researcher_tools node\n",
    "from open_deep_library.deep_researcher import researcher_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 7: compress_research\n",
    "\n",
    "**Purpose:** Compresses and synthesizes research findings into a concise, structured summary.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Configure compression model\n",
    "2. Add compression instruction to messages\n",
    "3. Attempt compression with retry logic:\n",
    "   - If token limit exceeded, remove older messages\n",
    "   - Retry up to 3 times\n",
    "4. Extract raw notes from tool and AI messages\n",
    "5. Return compressed research and raw notes\n",
    "\n",
    "**Why Compression?** Researchers may accumulate lots of tool outputs and reflections. Compression ensures:\n",
    "- All important information is preserved\n",
    "- Redundant information is deduplicated\n",
    "- Content stays within token limits for the final report\n",
    "\n",
    "**Token Limit Handling:** Gracefully handles token limit errors by progressively truncating messages.\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 511-585](open_deep_library/deep_researcher.py#L511-L585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the compress_research node\n",
    "from open_deep_library.deep_researcher import compress_research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 8: final_report_generation\n",
    "\n",
    "**Purpose:** Generates the final comprehensive research report from all collected findings.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Extract all notes from completed research\n",
    "2. Configure final report model\n",
    "3. Attempt report generation with retry logic:\n",
    "   - If token limit exceeded, truncate findings by 10%\n",
    "   - Retry up to 3 times\n",
    "4. Return final report or error message\n",
    "\n",
    "**Token Limit Strategy:**\n",
    "- First retry: Use model's token limit √ó 4 as character limit\n",
    "- Subsequent retries: Reduce by 10% each time\n",
    "- Graceful degradation with helpful error messages\n",
    "\n",
    "**Report Quality:** The prompt guides the model to create well-structured reports with:\n",
    "- Proper headings and sections\n",
    "- Inline citations\n",
    "- Comprehensive coverage of all findings\n",
    "- Sources section at the end\n",
    "\n",
    "**Implementation:** [`open_deep_library/deep_researcher.py` lines 607-697](open_deep_library/deep_researcher.py#L607-L697)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the final_report_generation node\n",
    "from open_deep_library.deep_researcher import final_report_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Graph Construction - Putting It All Together\n",
    "\n",
    "The system is organized into three interconnected graphs:\n",
    "\n",
    "### 1. Researcher Subgraph (Bottom Level)\n",
    "Handles individual focused research on a specific topic:\n",
    "```\n",
    "START ‚Üí researcher ‚Üí researcher_tools ‚Üí compress_research ‚Üí END\n",
    "               ‚Üë            ‚Üì\n",
    "               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò (loops until max iterations or ResearchComplete)\n",
    "```\n",
    "\n",
    "### 2. Supervisor Subgraph (Middle Level)\n",
    "Manages research delegation and coordination:\n",
    "```\n",
    "START ‚Üí supervisor ‚Üí supervisor_tools ‚Üí END\n",
    "            ‚Üë              ‚Üì\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò (loops until max iterations or ResearchComplete)\n",
    "            \n",
    "supervisor_tools spawns multiple researcher_subgraphs in parallel\n",
    "```\n",
    "\n",
    "### 3. Main Deep Researcher Graph (Top Level)\n",
    "Orchestrates the complete research workflow:\n",
    "```\n",
    "START ‚Üí clarify_with_user ‚Üí write_research_brief ‚Üí research_supervisor ‚Üí final_report_generation ‚Üí END\n",
    "                 ‚Üì                                       (supervisor_subgraph)\n",
    "               (may end early if clarification needed)\n",
    "```\n",
    "\n",
    "Let's import the compiled graphs from the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pre-compiled graphs from the library\n",
    "from open_deep_library.deep_researcher import (\n",
    "    # Bottom level: Individual researcher workflow\n",
    "    researcher_subgraph,    # Lines 588-605: researcher ‚Üí researcher_tools ‚Üí compress_research\n",
    "    \n",
    "    # Middle level: Supervisor coordination\n",
    "    supervisor_subgraph,    # Lines 351-363: supervisor ‚Üí supervisor_tools (spawns researchers)\n",
    "    \n",
    "    # Top level: Complete research workflow\n",
    "    deep_researcher,        # Lines 699-719: Main graph with all phases\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Architecture?\n",
    "\n",
    "### Advantages of Supervisor-Researcher Delegation\n",
    "\n",
    "1. **Dynamic Task Decomposition**\n",
    "   - Unlike section-based approaches with predefined structure, the supervisor can break down research based on the actual question\n",
    "   - Adapts to different types of research (comparisons, lists, deep dives, etc.)\n",
    "\n",
    "2. **Parallel Execution**\n",
    "   - Multiple researchers work simultaneously on different aspects\n",
    "   - Much faster than sequential section processing\n",
    "   - Configurable parallelism (1-20 concurrent researchers)\n",
    "\n",
    "3. **ReAct Pattern for Quality**\n",
    "   - Researchers use `think_tool` to reflect after each search\n",
    "   - Prevents excessive searching and improves search quality\n",
    "   - Natural stopping conditions based on information sufficiency\n",
    "\n",
    "4. **Flexible Tool Integration**\n",
    "   - Easy to add MCP tools for specialized research\n",
    "   - Supports multiple search APIs (Anthropic, Tavily)\n",
    "   - Each researcher can use different tool combinations\n",
    "\n",
    "5. **Graceful Token Limit Handling**\n",
    "   - Compression prevents token overflow\n",
    "   - Progressive truncation in final report generation\n",
    "   - Research can scale to arbitrary depths\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "- **Complexity:** More moving parts than section-based approach\n",
    "- **Cost:** Parallel researchers use more tokens (but faster)\n",
    "- **Unpredictability:** Research structure emerges dynamically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Running the Deep Researcher\n",
    "\n",
    "Now let's see the system in action! We'll use it to research wellness strategies for improving sleep quality.\n",
    "\n",
    "### Setup\n",
    "\n",
    "We need to:\n",
    "1. Set up the wellness research request\n",
    "2. Configure the execution with Anthropic settings\n",
    "3. Run the research workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Graph ready for execution\n",
      "  (Note: The graph is pre-compiled from the library)\n"
     ]
    }
   ],
   "source": [
    "# Set up the graph with Anthropic configuration\n",
    "from IPython.display import Markdown, display\n",
    "import uuid\n",
    "\n",
    "# Note: deep_researcher is already compiled from the library\n",
    "# For this demo, we'll use it directly without additional checkpointing\n",
    "graph = deep_researcher\n",
    "\n",
    "print(\"‚úì Graph ready for execution\")\n",
    "print(\"  (Note: The graph is pre-compiled from the library)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration for Anthropic\n",
    "\n",
    "We'll configure the system to use:\n",
    "- **Claude Sonnet 4** for all research, supervision, and report generation\n",
    "- **Tavily** for web search (you can also use Anthropic's native search)\n",
    "- **Moderate parallelism** (1 concurrent researcher for cost control)\n",
    "- **Clarification enabled** (will ask if research scope is unclear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration ready\n",
      "  - Research Model: GPT 5\n",
      "  - Max Concurrent Researchers: 1\n",
      "  - Max Iterations: 2\n",
      "  - Search API: Tavily\n"
     ]
    }
   ],
   "source": [
    "# Configure for Anthropic with moderate settings\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Model configuration - using Claude Sonnet 4 for everything\n",
    "        \"research_model\": \"openai:gpt-5\",\n",
    "        \"research_model_max_tokens\": 10000,\n",
    "        \n",
    "        \"compression_model\": \"openai:gpt-5\",\n",
    "        \"compression_model_max_tokens\": 8192,\n",
    "        \n",
    "        \"final_report_model\": \"openai:gpt-5\",\n",
    "        \"final_report_model_max_tokens\": 10000,\n",
    "        \n",
    "        \"summarization_model\": \"openai:gpt-5\",\n",
    "        \"summarization_model_max_tokens\": 8192,\n",
    "        \n",
    "        # Research behavior\n",
    "        \"allow_clarification\": True,\n",
    "        \"max_concurrent_research_units\": 1,  # 1 parallel researcher\n",
    "        \"max_researcher_iterations\": 2,      # Supervisor can delegate up to 2 times\n",
    "        \"max_react_tool_calls\": 3,           # Each researcher can make up to 3 tool calls\n",
    "        \n",
    "        # Search configuration\n",
    "        \"search_api\": \"tavily\",  # Using Tavily for web search\n",
    "        \"max_content_length\": 50000,\n",
    "        \n",
    "        # Thread ID for this conversation\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úì Configuration ready\")\n",
    "print(f\"  - Research Model: GPT 5\")\n",
    "print(f\"  - Max Concurrent Researchers: 1\")\n",
    "print(f\"  - Max Iterations: 2\")\n",
    "print(f\"  - Search API: Tavily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Wellness Research\n",
    "\n",
    "Now let's run the research! We'll ask the system to research evidence-based strategies for improving sleep quality.\n",
    "\n",
    "The workflow will:\n",
    "1. **Clarify** - Check if the request is clear (may skip if obvious)\n",
    "2. **Research Brief** - Transform our request into a structured brief\n",
    "3. **Supervisor** - Plan research strategy and delegate to researchers\n",
    "4. **Parallel Research** - Researchers gather information simultaneously\n",
    "5. **Compression** - Each researcher synthesizes their findings\n",
    "6. **Final Report** - All findings combined into comprehensive report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting research workflow...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Node: clarify_with_user\n",
      "============================================================\n",
      "\n",
      "I have sufficient information to proceed with your sleep improvement research request. I understand that you're looking for evidence-based strategies to address your current sleep challenges, which include inconsistent bedtimes (10pm-1am), phone use in bed, and morning fatigue. I will now research the most effective, scientifically-backed sleep hygiene practices and create a comprehensive, personalized sleep improvement plan that addresses your specific issues.\n",
      "\n",
      "============================================================\n",
      "Node: write_research_brief\n",
      "============================================================\n",
      "\n",
      "Research Brief Generated:\n",
      "I want to improve my sleep quality by developing a comprehensive, evidence-based sleep improvement plan. My current sleep challenges include: going to bed at inconsistent times (ranging from 10pm to 1am), using my phone in bed, and often feeling tired in the morning despite getting sleep. Please research the most effective, scientifically-backed sleep hygiene strategies and interventions that specifically address inconsistent bedtimes, electronic device use before sleep, and morning fatigue. I n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
      "WARNING:root:Summarization timed out after 60 seconds, returning original content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Node: research_supervisor\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Node: final_report_generation\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "FINAL REPORT GENERATED\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Error generating final report: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': \"This request would exceed your organization's rate limit of 30,000 input tokens per minute (org: 36a0367d-2b4e-43a2-aa03-a9c1a1c5ba6c, model: claude-sonnet-4-20250514). For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"}, 'request_id': 'req_011CXqUs7cwdNcqPBQvQLVjS'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Research workflow completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create our wellness research request\n",
    "research_request = \"\"\"\n",
    "I want to improve my sleep quality. I currently:\n",
    "- Go to bed at inconsistent times (10pm-1am)\n",
    "- Use my phone in bed\n",
    "- Often feel tired in the morning\n",
    "\n",
    "Please research the best evidence-based strategies for improving sleep quality and create a comprehensive sleep improvement plan for me.\n",
    "\"\"\"\n",
    "\n",
    "# Execute the graph\n",
    "async def run_research():\n",
    "    \"\"\"Run the research workflow and display results.\"\"\"\n",
    "    print(\"Starting research workflow...\\n\")\n",
    "    \n",
    "    async for event in graph.astream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": research_request}]},\n",
    "        config,\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        # Display each step\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Node: {node_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            if node_name == \"clarify_with_user\":\n",
    "                if \"messages\" in node_output:\n",
    "                    last_msg = node_output[\"messages\"][-1]\n",
    "                    print(f\"\\n{last_msg.content}\")\n",
    "            \n",
    "            elif node_name == \"write_research_brief\":\n",
    "                if \"research_brief\" in node_output:\n",
    "                    print(f\"\\nResearch Brief Generated:\")\n",
    "                    print(f\"{node_output['research_brief'][:500]}...\")\n",
    "            \n",
    "            elif node_name == \"supervisor\":\n",
    "                print(f\"\\nSupervisor planning research strategy...\")\n",
    "                if \"supervisor_messages\" in node_output:\n",
    "                    last_msg = node_output[\"supervisor_messages\"][-1]\n",
    "                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                        print(f\"Tool calls: {len(last_msg.tool_calls)}\")\n",
    "                        for tc in last_msg.tool_calls:\n",
    "                            print(f\"  - {tc['name']}\")\n",
    "            \n",
    "            elif node_name == \"supervisor_tools\":\n",
    "                print(f\"\\nExecuting supervisor's tool calls...\")\n",
    "                if \"notes\" in node_output:\n",
    "                    print(f\"Research notes collected: {len(node_output['notes'])}\")\n",
    "            \n",
    "            elif node_name == \"final_report_generation\":\n",
    "                if \"final_report\" in node_output:\n",
    "                    print(f\"\\n\" + \"=\"*60)\n",
    "                    print(\"FINAL REPORT GENERATED\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                    display(Markdown(node_output[\"final_report\"]))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Research workflow completed!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run the research\n",
    "await run_research()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Understanding the Output\n",
    "\n",
    "Let's break down what happened:\n",
    "\n",
    "### Phase 1: Clarification\n",
    "The system checked if your request was clear. Since you provided specific details about your sleep issues, it likely proceeded without asking clarifying questions.\n",
    "\n",
    "### Phase 2: Research Brief\n",
    "Your request was transformed into a detailed research brief that guides the supervisor's delegation strategy.\n",
    "\n",
    "### Phase 3: Supervisor Delegation\n",
    "The supervisor analyzed the brief and decided how to break down the research:\n",
    "- Used `think_tool` to plan strategy\n",
    "- Called `ConductResearch` to delegate to researchers\n",
    "- Each delegation specified a focused research topic (e.g., sleep hygiene, circadian rhythm, blue light effects)\n",
    "\n",
    "### Phase 4: Parallel Research\n",
    "Researchers worked on their assigned topics:\n",
    "- Each researcher used web search tools to gather information\n",
    "- Used `think_tool` to reflect after each search\n",
    "- Decided when they had enough information\n",
    "- Compressed their findings into clean summaries\n",
    "\n",
    "### Phase 5: Final Report\n",
    "All research findings were synthesized into a comprehensive sleep improvement plan with:\n",
    "- Well-structured sections\n",
    "- Evidence-based recommendations\n",
    "- Practical action items\n",
    "- Sources for further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Key Takeaways & Next Steps\n",
    "\n",
    "### Architecture Benefits\n",
    "1. **Dynamic Decomposition** - Research structure emerges from the question, not predefined\n",
    "2. **Parallel Efficiency** - Multiple researchers work simultaneously\n",
    "3. **ReAct Quality** - Strategic reflection improves search decisions\n",
    "4. **Scalability** - Handles token limits gracefully through compression\n",
    "5. **Flexibility** - Easy to add new tools and capabilities\n",
    "\n",
    "### When to Use This Pattern\n",
    "- **Complex research questions** that need multi-angle investigation\n",
    "- **Comparison tasks** where parallel research on different topics is beneficial\n",
    "- **Open-ended exploration** where structure should emerge dynamically\n",
    "- **Time-sensitive research** where parallel execution speeds up results\n",
    "\n",
    "### When to Use Section-Based Instead\n",
    "- **Highly structured reports** with predefined format requirements\n",
    "- **Template-based content** where sections are always the same\n",
    "- **Sequential dependencies** where later sections depend on earlier ones\n",
    "- **Budget constraints** where token efficiency is critical\n",
    "\n",
    "### Extend the System\n",
    "1. **Add MCP Tools** - Integrate specialized tools for your domain\n",
    "2. **Custom Prompts** - Modify prompts for specific research types\n",
    "3. **Different Models** - Try different Claude versions or mix models\n",
    "4. **Persistence** - Use a real database for checkpointing instead of memory\n",
    "\n",
    "### Learn More\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Open Deep Research Repo](https://github.com/langchain-ai/open_deep_research)\n",
    "- [Anthropic Claude Documentation](https://docs.anthropic.com/)\n",
    "- [Tavily Search API](https://tavily.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #3:\n",
    "\n",
    "What are the trade-offs of using parallel researchers vs. sequential research? When might you choose one approach over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "#### Parallel researchers\n",
    "- Pros: faster, independent exploration, fault-tolerant, better coverage\n",
    "- Cons: higher API costs, duplicate searches, coordination overhead, no knowledge sharing\n",
    "\n",
    "#### Sequential Research\n",
    "- Pros: lower cost, builds on findings, logical flow of events, handles dependencies\n",
    "- Cons: slower, bias accumulation, single point of failure, less diverse\n",
    "\n",
    "#### Decision:\n",
    "- Parallel: on independent questions, where speed matters, such as \"compare X vs Y\" tasks\n",
    "- Sequential: on logical dependencies, where budget matters, and narrative flow is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #4:\n",
    "\n",
    "How would you adapt this deep research architecture for a production wellness application? What additional components would you need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "- Horizontal scaling for multiple users\n",
    "- Docker containerization for consistent deployment across environments\n",
    "- User authentication\n",
    "- Replace in-memory stores with persistent storage\n",
    "- Logging (eg. built-in LangGraph)\n",
    "Extra:\n",
    "- Human-in-the-loop to flag uncertain recommendations for clinician review or reach out to depressive users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Activity #2: Custom Wellness Research\n",
    "\n",
    "Using what you've learned, run a custom wellness research task.\n",
    "\n",
    "**Requirements:**\n",
    "1. Create a wellness-related research question (exercise, nutrition, stress, etc.)\n",
    "2. Modify the configuration for your use case\n",
    "3. Run the research and analyze the output\n",
    "4. Document what worked well and what could be improved\n",
    "\n",
    "**Experiment ideas:**\n",
    "- Research exercise routines for specific conditions (bad knee, lower back pain)\n",
    "- Compare different stress management techniques\n",
    "- Investigate nutrition strategies for specific goals\n",
    "- Explore meditation and mindfulness research\n",
    "\n",
    "**YOUR CODE HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting research workflow...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Node: clarify_with_user\n",
      "============================================================\n",
      "\n",
      "To tailor an evidence-based plan for Hashimoto‚Äôs and prediabetes, could you share:\n",
      "\n",
      "- Age, sex, height, current weight, typical weekly activity level, and primary goal (lose/maintain/gain; target rate if losing)\n",
      "- Other health conditions or life stages (e.g., kidney disease, hypertension, high cholesterol, pregnancy/breastfeeding)\n",
      "- Meds/supplements: Do you take levothyroxine? What time? Any diabetes meds (e.g., metformin/GLP‚Äë1), iron or calcium supplements?\n",
      "- Diet restrictions/preferences: allergies or intolerances; vegetarian/vegan; gluten-free or diagnosed celiac; lactose intolerance; religious restrictions; any foods you avoid (e.g., soy)\n",
      "- Food likes/dislikes and preferred cuisines; budget and cooking time/skill; prefer quick meals or batch-cooking\n",
      "- Meal structure: meals/snacks per day; desired plan length (e.g., 7-day) and number of servings (just you or household)\n",
      "- Recent numbers (if known): A1C or fasting glucose\n",
      "\n",
      "============================================================\n",
      "Research workflow completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create your own wellness research request and run it\n",
    "\n",
    "my_wellness_request = \"\"\"\n",
    "I want to know what I can eat. I have:\n",
    "- autoimune Hashimoto's\n",
    "- prediabetic state\n",
    "\n",
    "Please research the best evidence-based nutrition strategies and create a comprehensive meal plan for me.\n",
    "\"\"\"\n",
    "\n",
    "# Optionally modify the config\n",
    "my_config = {\n",
    "    \"configurable\": {\n",
    "        \"research_model\": \"openai:gpt-5\",\n",
    "        \"research_model_max_tokens\": 10000,\n",
    "        \"compression_model\": \"openai:gpt-5\",\n",
    "        \"compression_model_max_tokens\": 8192,\n",
    "        \"final_report_model\": \"openai:gpt-5\",\n",
    "        \"final_report_model_max_tokens\": 10000,\n",
    "        \"summarization_model\": \"openai:gpt-5\",\n",
    "        \"summarization_model_max_tokens\": 8192,\n",
    "        \"allow_clarification\": True,\n",
    "        \"max_concurrent_research_units\": 1,\n",
    "        \"max_researcher_iterations\": 2,\n",
    "        \"max_react_tool_calls\": 3,\n",
    "        \"search_api\": \"tavily\",\n",
    "        \"max_content_length\": 50000,\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "async def run_custom_research(research_request, config):\n",
    "    \"\"\"Run the research workflow and display results.\"\"\"\n",
    "    print(\"Starting research workflow...\\n\")\n",
    "    \n",
    "    async for event in graph.astream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": research_request}]},\n",
    "        config,\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        # Display each step\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Node: {node_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            if node_name == \"clarify_with_user\":\n",
    "                if \"messages\" in node_output:\n",
    "                    last_msg = node_output[\"messages\"][-1]\n",
    "                    print(f\"\\n{last_msg.content}\")\n",
    "            \n",
    "            elif node_name == \"write_research_brief\":\n",
    "                if \"research_brief\" in node_output:\n",
    "                    print(f\"\\nResearch Brief Generated:\")\n",
    "                    print(f\"{node_output['research_brief'][:500]}...\")\n",
    "            \n",
    "            elif node_name == \"supervisor\":\n",
    "                print(f\"\\nSupervisor planning research strategy...\")\n",
    "                if \"supervisor_messages\" in node_output:\n",
    "                    last_msg = node_output[\"supervisor_messages\"][-1]\n",
    "                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                        print(f\"Tool calls: {len(last_msg.tool_calls)}\")\n",
    "                        for tc in last_msg.tool_calls:\n",
    "                            print(f\"  - {tc['name']}\")\n",
    "            \n",
    "            elif node_name == \"supervisor_tools\":\n",
    "                print(f\"\\nExecuting supervisor's tool calls...\")\n",
    "                if \"notes\" in node_output:\n",
    "                    print(f\"Research notes collected: {len(node_output['notes'])}\")\n",
    "            \n",
    "            elif node_name == \"final_report_generation\":\n",
    "                if \"final_report\" in node_output:\n",
    "                    print(f\"\\n\" + \"=\"*60)\n",
    "                    print(\"FINAL REPORT GENERATED\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                    display(Markdown(node_output[\"final_report\"]))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Research workflow completed!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run your research\n",
    "await run_custom_research(my_wellness_request, my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting research workflow...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Node: clarify_with_user\n",
      "============================================================\n",
      "\n",
      "Thanks‚Äîthis is sufficient to proceed. I understand you‚Äôre a 30-year-old female (161 cm, 68 kg), active (gym 2‚Äì3x/week plus walking), with Hashimoto‚Äôs thyroiditis and prediabetes, not on medication, omnivorous with a flexible gluten-free preference, primary goal of weight loss, and a preference for Asian cuisine with no other dietary restrictions. I‚Äôll now begin evidence-based research and create tailored nutrition strategies and a comprehensive meal plan for you.\n",
      "\n",
      "============================================================\n",
      "Node: write_research_brief\n",
      "============================================================\n",
      "\n",
      "Research Brief Generated:\n",
      "What are the best evidence-based nutrition strategies and a detailed, Asian-cuisine‚Äìforward, mostly gluten‚Äëfree (preference, flexible) omnivorous meal plan for me‚Äîa 30‚Äëyear‚Äëold female (161 cm, 68 kg; BMI ‚âà26.2), physically active (gym 2‚Äì3x/week plus walking), with autoimmune Hashimoto‚Äôs thyroiditis and prediabetes, on no medications‚Äîwhose primary goal is weight loss? Please: \n",
      "\n",
      "1) Determine energy needs and targets\n",
      "- Estimate my TDEE using validated equations (e.g., Mifflin‚ÄìSt Jeor) with an activ...\n",
      "\n",
      "============================================================\n",
      "Node: research_supervisor\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Node: final_report_generation\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "FINAL REPORT GENERATED\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Error generating final report: Connection error."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Research workflow completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create your own wellness research request and run it\n",
    "\n",
    "my_wellness_request = \"\"\"\n",
    "I want to know what I can eat. I have:\n",
    "- autoimune Hashimoto's\n",
    "- prediabetic state\n",
    "- Female, age: 30 years, 161cm, 68kgs\n",
    "- weekly activity: gym 2-3 times and walking\n",
    "- no meds\n",
    "- Diet: based on Hashimoto, it is prefered gluten-free\n",
    "- Gluten-free: preference/flexible\n",
    "- Primary goal: weight loss\n",
    "- dietary restrictions: none\n",
    "- eat animal products\n",
    "- food preferance: asian cuisine\n",
    "\n",
    "\n",
    "Please research the best evidence-based nutrition strategies and create a comprehensive meal plan for me.\n",
    "\"\"\"\n",
    "\n",
    "# Optionally modify the config\n",
    "my_config = {\n",
    "    \"configurable\": {\n",
    "        \"research_model\": \"openai:gpt-5\",\n",
    "        \"research_model_max_tokens\": 10000,\n",
    "        \"compression_model\": \"openai:gpt-5\",\n",
    "        \"compression_model_max_tokens\": 8192,\n",
    "        \"final_report_model\": \"openai:gpt-5\",\n",
    "        \"final_report_model_max_tokens\": 10000,\n",
    "        \"summarization_model\": \"openai:gpt-5\",\n",
    "        \"summarization_model_max_tokens\": 8192,\n",
    "        \"allow_clarification\": True,\n",
    "        \"max_concurrent_research_units\": 1,\n",
    "        \"max_researcher_iterations\": 2,\n",
    "        \"max_react_tool_calls\": 3,\n",
    "        \"search_api\": \"tavily\",\n",
    "        \"max_content_length\": 50000,\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "async def run_custom_research(research_request, config):\n",
    "    \"\"\"Run the research workflow and display results.\"\"\"\n",
    "    print(\"Starting research workflow...\\n\")\n",
    "    \n",
    "    async for event in graph.astream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": research_request}]},\n",
    "        config,\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        # Display each step\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Node: {node_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            if node_name == \"clarify_with_user\":\n",
    "                if \"messages\" in node_output:\n",
    "                    last_msg = node_output[\"messages\"][-1]\n",
    "                    print(f\"\\n{last_msg.content}\")\n",
    "            \n",
    "            elif node_name == \"write_research_brief\":\n",
    "                if \"research_brief\" in node_output:\n",
    "                    print(f\"\\nResearch Brief Generated:\")\n",
    "                    print(f\"{node_output['research_brief'][:500]}...\")\n",
    "            \n",
    "            elif node_name == \"supervisor\":\n",
    "                print(f\"\\nSupervisor planning research strategy...\")\n",
    "                if \"supervisor_messages\" in node_output:\n",
    "                    last_msg = node_output[\"supervisor_messages\"][-1]\n",
    "                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                        print(f\"Tool calls: {len(last_msg.tool_calls)}\")\n",
    "                        for tc in last_msg.tool_calls:\n",
    "                            print(f\"  - {tc['name']}\")\n",
    "            \n",
    "            elif node_name == \"supervisor_tools\":\n",
    "                print(f\"\\nExecuting supervisor's tool calls...\")\n",
    "                if \"notes\" in node_output:\n",
    "                    print(f\"Research notes collected: {len(node_output['notes'])}\")\n",
    "            \n",
    "            elif node_name == \"final_report_generation\":\n",
    "                if \"final_report\" in node_output:\n",
    "                    print(f\"\\n\" + \"=\"*60)\n",
    "                    print(\"FINAL REPORT GENERATED\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                    display(Markdown(node_output[\"final_report\"]))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Research workflow completed!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run your research\n",
    "await run_custom_research(my_wellness_request, my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting research workflow...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Node: clarify_with_user\n",
      "============================================================\n",
      "\n",
      "Thank you‚Äîthis is sufficient to proceed. I understand you‚Äôre a 30-year-old female (161 cm, 68 kg) with autoimmune Hashimoto‚Äôs (no meds) and prediabetes, aiming for weight loss. You‚Äôre active (gym 2‚Äì3x/week + walking), prefer Asian cuisine, eat animal products, and are flexible with gluten-free. I will now begin evidence-based research and prepare a comprehensive nutrition strategy and meal plan aligned with your goals and preferences.\n",
      "\n",
      "============================================================\n",
      "Node: write_research_brief\n",
      "============================================================\n",
      "\n",
      "Research Brief Generated:\n",
      "What are the most robust, up-to-date (through 2026) evidence-based nutrition strategies and a practical, culturally aligned meal plan for me‚Äîa 30-year-old female, 161 cm, 68 kg (BMI ~26), with autoimmune Hashimoto‚Äôs thyroiditis (not on thyroid medication) and prediabetes‚Äîwhose primary goal is weight loss; who exercises at the gym 2‚Äì3 times per week plus walking; eats animal products; has no dietary restrictions; prefers Asian cuisine; and prefers but is flexible about gluten-free eating?\n",
      "\n",
      "Please...\n",
      "\n",
      "============================================================\n",
      "Node: research_supervisor\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Node: final_report_generation\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "FINAL REPORT GENERATED\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Comprehensive Nutrition Strategy and Meal Plan for Weight Loss and Glycemic Control\n",
       "\n",
       "## Introduction\n",
       "\n",
       "For a 30-year-old female with autoimmune Hashimoto‚Äôs thyroiditis and prediabetes, effective management of weight and glycemic control through diet is crucial. This report provides a comprehensive nutrition strategy, focusing on evidence-based dietary patterns, macronutrient distribution, and meal timing to support her weight loss goals. The preferences for Asian cuisine and flexibility with gluten-free eating will be integrated into a practical, culturally aligning meal plan.\n",
       "\n",
       "## Evidence Synthesis and Rationale\n",
       "\n",
       "### Dietary Patterns and Weight/Glycemic Outcomes in Prediabetes\n",
       "\n",
       "- **Calorie-Restricted Diets**: Evidence supports that a calorie deficit of approximately 20% or about 500 kcal/day is effective for weight loss, improving insulin sensitivity and reducing A1c levels.\n",
       "- **Mediterranean Diet**: Rich in healthy fats (MUFA/PUFA), this diet improves glycemic control and cardiovascular health. It's linked with improved A1c and lipid profiles and can be adapted to include Asian flavors.\n",
       "- **Low-Carb/Low-GI Diets**: These diets are beneficial in lowering fasting glucose and A1c. Prioritizing low-GI Asian staples such as basmati rice over high-GI jasmine rice can be effective.\n",
       "- **High-Protein Diets**: Consuming 1.2‚Äì1.6 g/kg/day, with protein evenly distributed across meals, supports satiety and lean mass retention during weight loss phases.\n",
       "\n",
       "### Carbohydrate Quality and Distribution\n",
       "\n",
       "- **Daily Carbohydrate Intake**: Aim for 130‚Äì150 g of carbohydrates per day, distributed evenly (30‚Äì45 g per meal) to maintain stable blood glucose levels.\n",
       "- **Glycemic Index/Load**: Choose low to medium-GI foods. Asian staples like soba noodles or brown rice are preferable to jasmine rice and instant noodles.\n",
       "- **Fiber Intake**: Target 25‚Äì35 g/day to aid in glycemic control and weight management. Incorporate fiber-rich legumes and vegetables.\n",
       "- **Added Sugar Limit**: Keep to less than 25 g/day.\n",
       "\n",
       "### Protein Needs for Weight Loss and Glycemic Control\n",
       "\n",
       "- **Protein Target**: 1.2‚Äì1.6 g/kg/day, promoting muscle retention. Include animal-based (fish, chicken) and plant-based proteins (tofu, legumes).\n",
       "- **Protein Distribution**: Approximately 20‚Äì35 g per meal to enhance satiety.\n",
       "\n",
       "### Fat Quality and Sodium Considerations\n",
       "\n",
       "- **Fat Quality**: Increase MUFAs from sources like sesame oil and PUFAs from fatty fish. Include omega-3-rich foods at least twice a week.\n",
       "- **Sodium**: Limit to 1500‚Äì2300 mg/day, especially considering high-sodium Asian condiments. Use low-sodium soy sauce or tamari.\n",
       "\n",
       "### Hashimoto‚Äôs-Specific Considerations\n",
       "\n",
       "- **Gluten-Free Diet**: While there‚Äôs no conclusive evidence for gluten-free benefits in non-celiac Hashimoto‚Äôs patients, many choose to eliminate gluten to potentially reduce thyroid antibodies. Supplement with nutrient-rich gluten-free grains to avoid deficiencies.\n",
       "- **Micronutrients**: Balance the intake of iodine, selenium, zinc, iron, vitamin D, and B12, essential for thyroid health.\n",
       "  - **Iodine**: Avoid excess. Do not exceed 150 mcg/day without medical supervision.\n",
       "  - **Selenium**: 55 mcg/day from sources like Brazil nuts and seafood.\n",
       "  - **Zinc**: 8 mg/day from meat and seeds.\n",
       "  - **Vitamin D**: Consider supplementation if dietary sunlight exposure is inadequate.\n",
       "- **Goitrogens and Soy**: Cooking reduces goitrogenic effects. Soy can be included unless further adverse effects are noted.\n",
       "\n",
       "### Meal Timing Strategies\n",
       "\n",
       "- **Time-Restricted Eating (TRE)**: Adopting early eating windows (8 am ‚Äì 4 pm) may enhance weight loss and glycemic control, according to recent trials.\n",
       "\n",
       "## Individualization and Targets\n",
       "\n",
       "### Energy Needs and Caloric Deficit\n",
       "\n",
       "- **Energy Needs**: Using the Mifflin-St Jeor equation, estimated daily caloric needs are about 1900 kcal/day, assuming moderate activity. Aiming for 1400‚Äì1500 kcal/day can yield effective weight loss.\n",
       "\n",
       "### Macronutrient Distribution\n",
       "\n",
       "- **Carbohydrates**: 35-40% of total intake; focus on low-GI, high-fiber foods.\n",
       "- **Proteins**: 25-30% to support muscle mass retention.\n",
       "- **Fats**: 30-35% with an emphasis on healthy fats.\n",
       "\n",
       "## Practical Outputs\n",
       "\n",
       "### 7-Day Meal Plan\n",
       "\n",
       "Create a 7-day meal plan comprising gluten-free alternatives with Asian cuisine influences and dairy options. Include:\n",
       "\n",
       "- **Breakfasts**: Incorporate high-protein, low-GI ingredients (e.g., egg and tofu stir fry).\n",
       "- **Lunches/Dinners**: Balance lean proteins, vegetables, and low-GI carbohydrates (e.g., soba noodles with chicken and vegetables).\n",
       "- **Snacks**: Opt for nuts, mixed seeds, and yogurt.\n",
       "\n",
       "### Grocery List and Meal Prep\n",
       "\n",
       "Compile a list of core ingredients for the meal plan and a preparation guide focusing on batch cooking and easy-to-make meals.\n",
       "\n",
       "### Dining Out Tips\n",
       "\n",
       "- Choose dishes centered around lean proteins and vegetables.\n",
       "- Request modifications like steamed rice instead of fried rice.\n",
       "- Use gluten-free tamari in place of regular soy sauce when available.\n",
       "\n",
       "### Monitoring and Adjustments\n",
       "\n",
       "- Track weight, waist circumference, and glucose levels regularly.\n",
       "- Schedule periodic follow-ups with healthcare providers to monitor thyroid function and adjust dietary micronutrient intake accordingly.\n",
       "\n",
       "## Sources\n",
       "\n",
       "[1] ADA Standards of Care: URL  \n",
       "[2] American Thyroid Association Guidelines: URL  \n",
       "[3] Cochrane Review on Diet in Prediabetes: URL  \n",
       "[4] University of Sydney Glycemic Index Database: URL  \n",
       "[5] NIH Office of Dietary Supplements Fact Sheets: URL"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Research workflow completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create your own wellness research request and run it\n",
    "\n",
    "my_wellness_request = \"\"\"\n",
    "I want to know what I can eat. I have:\n",
    "- autoimune Hashimoto's\n",
    "- prediabetic state\n",
    "- Female, age: 30 years, 161cm, 68kgs\n",
    "- weekly activity: gym 2-3 times and walking\n",
    "- no meds\n",
    "- Diet: based on Hashimoto, it is prefered gluten-free\n",
    "- Gluten-free: preference/flexible\n",
    "- Primary goal: weight loss\n",
    "- dietary restrictions: none\n",
    "- eat animal products\n",
    "- food preferance: asian cuisine\n",
    "\n",
    "\n",
    "Please research the best evidence-based nutrition strategies and create a comprehensive meal plan for me.\n",
    "\"\"\"\n",
    "\n",
    "# Optionally modify the config\n",
    "my_config = {\n",
    "    \"configurable\": {\n",
    "        \"research_model\": \"openai:gpt-5\",\n",
    "        \"research_model_max_tokens\": 10000,\n",
    "        \"compression_model\": \"openai:gpt-5\",\n",
    "        \"compression_model_max_tokens\": 8192,\n",
    "        \"final_report_model\": \"openai:gpt-4o\",  # ‚Üê Try more reliable model\n",
    "        \"final_report_model_max_tokens\": 8000,  # ‚Üê Reduce tokens to speed up\n",
    "        \"summarization_model\": \"openai:gpt-5\",\n",
    "        \"summarization_model_max_tokens\": 8192,\n",
    "        \"allow_clarification\": True,\n",
    "        \"max_concurrent_research_units\": 1,\n",
    "        \"max_researcher_iterations\": 2,\n",
    "        \"max_react_tool_calls\": 3,\n",
    "        \"search_api\": \"tavily\",\n",
    "        \"max_content_length\": 30000,  # ‚Üê Reduce to prevent timeout\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        # Add these:\n",
    "        \"request_timeout\": 120,  # 2 minutes\n",
    "        \"max_retries\": 3\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "async def run_custom_research(research_request, config):\n",
    "    \"\"\"Run the research workflow and display results.\"\"\"\n",
    "    print(\"Starting research workflow...\\n\")\n",
    "    \n",
    "    async for event in graph.astream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": research_request}]},\n",
    "        config,\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        final_state = event\n",
    "        # Display each step\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Node: {node_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            if node_name == \"clarify_with_user\":\n",
    "                if \"messages\" in node_output:\n",
    "                    last_msg = node_output[\"messages\"][-1]\n",
    "                    print(f\"\\n{last_msg.content}\")\n",
    "            \n",
    "            elif node_name == \"write_research_brief\":\n",
    "                if \"research_brief\" in node_output:\n",
    "                    print(f\"\\nResearch Brief Generated:\")\n",
    "                    print(f\"{node_output['research_brief'][:500]}...\")\n",
    "            \n",
    "            elif node_name == \"supervisor\":\n",
    "                print(f\"\\nSupervisor planning research strategy...\")\n",
    "                if \"supervisor_messages\" in node_output:\n",
    "                    last_msg = node_output[\"supervisor_messages\"][-1]\n",
    "                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                        print(f\"Tool calls: {len(last_msg.tool_calls)}\")\n",
    "                        for tc in last_msg.tool_calls:\n",
    "                            print(f\"  - {tc['name']}\")\n",
    "            \n",
    "            elif node_name == \"supervisor_tools\":\n",
    "                print(f\"\\nExecuting supervisor's tool calls...\")\n",
    "                if \"notes\" in node_output:\n",
    "                    print(f\"Research notes collected: {len(node_output['notes'])}\")\n",
    "            \n",
    "            elif node_name == \"final_report_generation\":\n",
    "                if \"final_report\" in node_output:\n",
    "                    print(f\"\\n\" + \"=\"*60)\n",
    "                    print(\"FINAL REPORT GENERATED\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                    display(Markdown(node_output[\"final_report\"]))\n",
    "                else:\n",
    "                    # ‚Üê Add error handling here\n",
    "                    print(\"‚ö†Ô∏è Final report generation had an issue\")\n",
    "                    if \"notes\" in node_output:\n",
    "                        print(f\"‚úÖ Research completed: {len(node_output.get('notes', ''))} chars\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Research workflow completed!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return final_state  # ‚Üê Return the state\n",
    "\n",
    "# Run your research\n",
    "final_state = await run_custom_research(my_wellness_request, my_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
